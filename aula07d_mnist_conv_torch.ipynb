{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLpOBBOOYnQNSwbFEZZszS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/aulasann/blob/main/aula07d_mnist_conv_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V0J4UV_i-G9",
        "outputId": "f42ec07c-f554-4c2d-caa8-0292874e263e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxWhvA1B_Gz6",
        "outputId": "4b6a36da-322c-403b-8095-239c09bec200"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class TorchCNN2D(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(TorchCNN2D, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=4)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(in_features=4*25*25, out_features=512)\n",
        "    self.fc2 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.flatten(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = F.softmax(x, dim=1)\n",
        "    return x\n",
        "\n",
        "class TorchWrappedNN(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, epochs=5, batch_size=128, model_fabric=TorchCNN2D):\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.model_fabric = model_fabric\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.labels, ids = torch.unique(torch.tensor(y), return_inverse=True)\n",
        "    self.model = self.model_fabric(len(self.labels)).to(device)\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.optimizer = optim.RMSprop(self.model.parameters(), lr=0.001)\n",
        "\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X, dtype=torch.float32),\n",
        "        torch.tensor(ids, dtype=torch.long))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=self.batch_size)\n",
        "    for epoch in range(self.epochs):\n",
        "      for data in train_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    with torch.no_grad():\n",
        "      inputs = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "      outputs = self.model(inputs)\n",
        "      return self.labels[torch.argmax(outputs, dim=1).cpu().numpy()]\n"
      ],
      "metadata": {
        "id": "pkskFA3d_QVC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "class Divide255(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    return X / 255.0\n",
        "\n",
        "class Shape2Torch(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    return X.reshape((-1, 1, 28, 28))\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", Divide255()),\n",
        "    (\"shape2Torch\", Shape2Torch()),\n",
        "    (\"model\", TorchWrappedNN())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_images, train_labels)\n",
        "y_pred = pipeline.predict(test_images)\n",
        "accuracy_score(test_labels, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmHDbLiQtaPK",
        "outputId": "cb0fe347-a55c-4e29-da3e-7d56d51a9b65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2454868802.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(ids, dtype=torch.long))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9823"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TorchCNN2D(nn.Module):\n",
        "  def __init__(self, input_shape, output_shape):\n",
        "    super(TorchCNN2D, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=input_shape[0],\n",
        "                           out_channels=32, kernel_size=3)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Linear(in_features=1152, out_features=output_shape)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc(x)\n",
        "    x = F.softmax(x, dim=1)\n",
        "    return x\n",
        "\n",
        "input_shape = (1, 28, 28)\n",
        "output_shape = 10\n",
        "model = TorchCNN2D(input_shape, output_shape)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1RkVziWDRdq",
        "outputId": "0ce08afc-b162-4d96-cfb6-58bc156dac91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TorchCNN2D(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc): Linear(in_features=1152, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TorchWrappedNN(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, epochs=5, batch_size=128, model_fabric=TorchCNN2D):\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.model_fabric = model_fabric\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.labels, ids = torch.unique(torch.tensor(y), return_inverse=True)\n",
        "    self.model = self.model_fabric(X.shape[1:], len(self.labels)).to(device)\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.optimizer = optim.RMSprop(self.model.parameters(), lr=0.001)\n",
        "\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X, dtype=torch.float32),\n",
        "        torch.tensor(ids, dtype=torch.long))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=self.batch_size)\n",
        "    for epoch in range(self.epochs):\n",
        "      for data in train_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    with torch.no_grad():\n",
        "      inputs = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "      outputs = self.model(inputs)\n",
        "      return self.labels[torch.argmax(outputs, dim=1).cpu().numpy()]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", Divide255()),\n",
        "    (\"shape2Torch\", Shape2Torch()),\n",
        "    (\"model\", TorchWrappedNN())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_images, train_labels)\n",
        "y_pred = pipeline.predict(test_images)\n",
        "accuracy_score(test_labels, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtMB7u6IEbsi",
        "outputId": "6c3ca050-b3b8-4008-ddc8-83a06531e987"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-714792585.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(ids, dtype=torch.long))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9887"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}