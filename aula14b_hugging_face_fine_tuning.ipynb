{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "aula14b - hugging face fine tuning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/aulasann/blob/main/aula14b_hugging_face_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"stanfordnlp/imdb\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:14.959558Z",
          "iopub.execute_input": "2025-07-07T23:31:14.95987Z",
          "iopub.status.idle": "2025-07-07T23:31:20.768005Z",
          "shell.execute_reply.started": "2025-07-07T23:31:14.959851Z",
          "shell.execute_reply": "2025-07-07T23:31:20.767338Z"
        },
        "id": "uuvYJStMYt-M",
        "outputId": "a93dc1b4-df6c-433d-e54c-5ad8238da204",
        "colab": {
          "referenced_widgets": [
            "ed00dd4488044a8dbecd2ecfc99cfd22",
            "0ebb16a5631c4679a5037b5e3f961878",
            "561da2ccaaa54d0b9dc41a5a11509d43",
            "511793d9c7aa4417b79fb122fb0627d5",
            "bdc4c389129e45b5934879c358952433",
            "41bc636d75964d86bf2cb07cac9080fe",
            "8a37ed57239943d288fd128fa7e0cafe"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed00dd4488044a8dbecd2ecfc99cfd22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ebb16a5631c4679a5037b5e3f961878"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "561da2ccaaa54d0b9dc41a5a11509d43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "511793d9c7aa4417b79fb122fb0627d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdc4c389129e45b5934879c358952433"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41bc636d75964d86bf2cb07cac9080fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a37ed57239943d288fd128fa7e0cafe"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train\"][100]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:20.768663Z",
          "iopub.execute_input": "2025-07-07T23:31:20.769015Z",
          "iopub.status.idle": "2025-07-07T23:31:20.774234Z",
          "shell.execute_reply.started": "2025-07-07T23:31:20.768996Z",
          "shell.execute_reply": "2025-07-07T23:31:20.773724Z"
        },
        "id": "sUvvwrohYt-M",
        "outputId": "9b6618ba-a301-436a-abb8-4978b40679b9"
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'text': \"Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to expand on that I don't know. This is already a waste of my time. I just wanted to warn others. Avoid this movie. The acting sucks and the writing is just moronic. Bad in every way. The only nice thing about the movie are Deniz Akkaya's breasts. Even that was ruined though by a terrible and unneeded rape scene. The movie is a poorly contrived and totally unbelievable piece of garbage.<br /><br />OK now I am just going to rag on IMDb for this stupid rule of 10 lines of text minimum. First I waste my time watching this offal. Then feeling compelled to warn others I create an account with IMDb only to discover that I have to write a friggen essay on the film just to express how bad I think it is. Totally unnecessary.\",\n 'label': 0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:20.775869Z",
          "iopub.execute_input": "2025-07-07T23:31:20.77635Z",
          "iopub.status.idle": "2025-07-07T23:31:20.790343Z",
          "shell.execute_reply.started": "2025-07-07T23:31:20.776327Z",
          "shell.execute_reply": "2025-07-07T23:31:20.789681Z"
        },
        "id": "j0-LI8R-Yt-M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "def tokenize_dataset(data):\n",
        "    # Keys of the returned dictionary will be added to the dataset as columns\n",
        "    return tokenizer(data[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "dataset = ds.map(tokenize_dataset)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:20.790906Z",
          "iopub.execute_input": "2025-07-07T23:31:20.791132Z",
          "iopub.status.idle": "2025-07-07T23:33:28.317802Z",
          "shell.execute_reply.started": "2025-07-07T23:31:20.791115Z",
          "shell.execute_reply": "2025-07-07T23:33:28.316864Z"
        },
        "id": "6LK1lawvYt-M",
        "outputId": "62cf89f6-8d84-4817-f164-88601d3d7686",
        "colab": {
          "referenced_widgets": [
            "7b03de87cf254c27a75e3316d8e37f84",
            "4d4fbab27cb44e8c87baa040bd47bcc8",
            "78f99b6f27e34078ac7b6e2930bb9be1",
            "af8bd1594ed144828b3aa834bc7713f8",
            "2ace2cf004784a54b874c569beac8b0e",
            "2ccf23ed68e8479fbe1ff365bec4768f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b03de87cf254c27a75e3316d8e37f84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d4fbab27cb44e8c87baa040bd47bcc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78f99b6f27e34078ac7b6e2930bb9be1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af8bd1594ed144828b3aa834bc7713f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ace2cf004784a54b874c569beac8b0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ccf23ed68e8479fbe1ff365bec4768f"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Load and compile our model\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(base_model)\n",
        "\n",
        "tf_dataset = model.prepare_tf_dataset(\n",
        "    dataset[\"train\"],\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "tf_val_dataset = model.prepare_tf_dataset(\n",
        "    dataset[\"validation\"],  # ou \"test\" se não houver \"validation\"\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"melhor_modelo.h5\",         # Caminho onde o modelo será salvo\n",
        "    monitor=\"val_loss\",                  # Métrica a ser monitorada\n",
        "    save_best_only=True,                 # Salva apenas o melhor modelo\n",
        "    save_weights_only=False,             # Salva o modelo completo (não só os pesos)\n",
        "    mode=\"min\",                          # Queremos minimizar a val_loss\n",
        "    verbose=1                            # Mostra mensagens durante o salvamento\n",
        ")\n",
        "\n",
        "# Lower learning rates are often better for fine-tuning transformers\n",
        "model.compile()  # No loss argument!\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_val_dataset,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "melhor_modelo = load_model(\"melhor_modelo.h5\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:33:28.318463Z",
          "iopub.execute_input": "2025-07-07T23:33:28.318721Z",
          "iopub.status.idle": "2025-07-07T23:47:39.70765Z",
          "shell.execute_reply.started": "2025-07-07T23:33:28.318701Z",
          "shell.execute_reply": "2025-07-07T23:47:39.706989Z"
        },
        "id": "VYzn_gtNYt-N",
        "outputId": "4867ea1e-5ff3-41f0-ed7a-239bc553ba6c",
        "colab": {
          "referenced_widgets": [
            "cf3a9ccce289487db01cc1868fc3fe40"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-07-07 23:33:30.061119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751931210.226350      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751931210.277383      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf3a9ccce289487db01cc1868fc3fe40"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1751931224.746483      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nAll PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751931241.523433     126 service.cc:148] XLA service 0x7d3d16063a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1751931241.523907     126 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1751931241.592800     126 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1751931241.703043     126 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "1562/1562 [==============================] - 834s 521ms/step - loss: 0.6986\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf_keras.src.callbacks.History at 0x7d3d1c1618d0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf_test_dataset = model.prepare_tf_dataset(\n",
        "    dataset[\"test\"],\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:56:24.287608Z",
          "iopub.execute_input": "2025-07-07T23:56:24.287889Z",
          "iopub.status.idle": "2025-07-07T23:56:24.358472Z",
          "shell.execute_reply.started": "2025-07-07T23:56:24.287868Z",
          "shell.execute_reply": "2025-07-07T23:56:24.357915Z"
        },
        "id": "HcHhaIHYYt-N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo no conjunto de teste\n",
        "results = model.evaluate(tf_test_dataset)\n",
        "print(\"Resultados da avaliação:\", results)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:56:38.256016Z",
          "iopub.execute_input": "2025-07-07T23:56:38.256353Z",
          "iopub.status.idle": "2025-07-08T00:01:17.696646Z",
          "shell.execute_reply.started": "2025-07-07T23:56:38.256329Z",
          "shell.execute_reply": "2025-07-08T00:01:17.695865Z"
        },
        "id": "xYZT9U6DYt-N",
        "outputId": "f6ff4299-5a3f-4d2f-81d8-3c42f20af76a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "1563/1563 [==============================] - 279s 177ms/step - loss: 0.6939\nResultados da avaliação: 0.693935751914978\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "clf_pipeline = pipeline(\n",
        "    task=\"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_all_scores=True  # Opcional: retorna scores para todas as classes\n",
        ")\n",
        "\n",
        "# Exemplo de uso\n",
        "texts = [\n",
        "    \"This movie is excellent!\",\n",
        "    \"The movie was horrible and boring.\"\n",
        "]\n",
        "\n",
        "results = clf_pipeline(texts)\n",
        "\n",
        "for text, res in zip(texts, results):\n",
        "    print(f\"\\nTexto: {text}\")\n",
        "    for label_score in res:\n",
        "        print(f\"  → {label_score['label']}: {label_score['score']:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-08T00:02:27.679848Z",
          "iopub.execute_input": "2025-07-08T00:02:27.680609Z",
          "iopub.status.idle": "2025-07-08T00:02:32.38471Z",
          "shell.execute_reply.started": "2025-07-08T00:02:27.680573Z",
          "shell.execute_reply": "2025-07-08T00:02:32.384059Z"
        },
        "id": "v3mL8nKlYt-N",
        "outputId": "ebb3632c-3962-477b-874c-e94b17e135a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Device set to use 0\n/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nTexto: This movie is excellent!\n  → NEGATIVE: 0.5197\n  → POSITIVE: 0.4803\n\nTexto: The movie was horrible and boring.\n  → NEGATIVE: 0.5197\n  → POSITIVE: 0.4803\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"analise_sentimento_imdb_1epoca\")\n",
        "tokenizer.save_pretrained(\"analise_sentimento_imdb_1epoca\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-08T00:06:12.998334Z",
          "iopub.execute_input": "2025-07-08T00:06:12.998915Z",
          "iopub.status.idle": "2025-07-08T00:06:13.584847Z",
          "shell.execute_reply.started": "2025-07-08T00:06:12.998891Z",
          "shell.execute_reply": "2025-07-08T00:06:13.584126Z"
        },
        "id": "3jbvTetnYt-N",
        "outputId": "813c3dab-6888-4276-88f9-3e42d983fd5b"
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('analise_sentimento_imdb_1epoca/tokenizer_config.json',\n 'analise_sentimento_imdb_1epoca/special_tokens_map.json',\n 'analise_sentimento_imdb_1epoca/vocab.txt',\n 'analise_sentimento_imdb_1epoca/added_tokens.json',\n 'analise_sentimento_imdb_1epoca/tokenizer.json')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pipeline = pipeline(\"text-classification\", model=\"analise_sentimento_imdb_1epoca\", tokenizer=\"analise_sentimento_imdb_1epoca\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-08T00:06:33.821896Z",
          "iopub.execute_input": "2025-07-08T00:06:33.822641Z",
          "iopub.status.idle": "2025-07-08T00:06:35.287048Z",
          "shell.execute_reply.started": "2025-07-08T00:06:33.822609Z",
          "shell.execute_reply": "2025-07-08T00:06:35.286431Z"
        },
        "id": "Z-e8js7cYt-O",
        "outputId": "ec99150b-00ca-4bde-bcc3-4d3a1a7c2636"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some layers from the model checkpoint at analise_sentimento_imdb_1epoca were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at analise_sentimento_imdb_1epoca and are newly initialized: ['dropout_39']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use 0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pipeline(\"This is a great movie!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-08T00:07:45.374112Z",
          "iopub.execute_input": "2025-07-08T00:07:45.374747Z",
          "iopub.status.idle": "2025-07-08T00:07:45.499901Z",
          "shell.execute_reply.started": "2025-07-08T00:07:45.374712Z",
          "shell.execute_reply": "2025-07-08T00:07:45.499136Z"
        },
        "id": "XBnR1vdTYt-O",
        "outputId": "616458a6-7ba0-49a4-c7c3-37abc7d36208"
      },
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[{'label': 'NEGATIVE', 'score': 0.5197456479072571}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}