{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "aula14b - hugging face fine tuning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/aulasann/blob/main/aula14b_hugging_face_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"stanfordnlp/imdb\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:14.959558Z",
          "iopub.execute_input": "2025-07-07T23:31:14.95987Z",
          "iopub.status.idle": "2025-07-07T23:31:20.768005Z",
          "shell.execute_reply.started": "2025-07-07T23:31:14.959851Z",
          "shell.execute_reply": "2025-07-07T23:31:20.767338Z"
        },
        "colab": {
          "referenced_widgets": [
            "ed00dd4488044a8dbecd2ecfc99cfd22",
            "0ebb16a5631c4679a5037b5e3f961878",
            "561da2ccaaa54d0b9dc41a5a11509d43",
            "511793d9c7aa4417b79fb122fb0627d5",
            "bdc4c389129e45b5934879c358952433",
            "41bc636d75964d86bf2cb07cac9080fe",
            "8a37ed57239943d288fd128fa7e0cafe"
          ]
        },
        "id": "KrZc11RURLu-",
        "outputId": "811e2261-a069-4df8-e06a-14057e30f4fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed00dd4488044a8dbecd2ecfc99cfd22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ebb16a5631c4679a5037b5e3f961878"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "561da2ccaaa54d0b9dc41a5a11509d43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "511793d9c7aa4417b79fb122fb0627d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdc4c389129e45b5934879c358952433"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41bc636d75964d86bf2cb07cac9080fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a37ed57239943d288fd128fa7e0cafe"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train\"][100]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:20.768663Z",
          "iopub.execute_input": "2025-07-07T23:31:20.769015Z",
          "iopub.status.idle": "2025-07-07T23:31:20.774234Z",
          "shell.execute_reply.started": "2025-07-07T23:31:20.768996Z",
          "shell.execute_reply": "2025-07-07T23:31:20.773724Z"
        },
        "id": "GFLw5PqSRLu-",
        "outputId": "e9f59bb2-c14d-458b-b55d-465d3fdfc93e"
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'text': \"Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to expand on that I don't know. This is already a waste of my time. I just wanted to warn others. Avoid this movie. The acting sucks and the writing is just moronic. Bad in every way. The only nice thing about the movie are Deniz Akkaya's breasts. Even that was ruined though by a terrible and unneeded rape scene. The movie is a poorly contrived and totally unbelievable piece of garbage.<br /><br />OK now I am just going to rag on IMDb for this stupid rule of 10 lines of text minimum. First I waste my time watching this offal. Then feeling compelled to warn others I create an account with IMDb only to discover that I have to write a friggen essay on the film just to express how bad I think it is. Totally unnecessary.\",\n 'label': 0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:20.775869Z",
          "iopub.execute_input": "2025-07-07T23:31:20.77635Z",
          "iopub.status.idle": "2025-07-07T23:31:20.790343Z",
          "shell.execute_reply.started": "2025-07-07T23:31:20.776327Z",
          "shell.execute_reply": "2025-07-07T23:31:20.789681Z"
        },
        "id": "DeA1l4rHRLu-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "def tokenize_dataset(data):\n",
        "    # Keys of the returned dictionary will be added to the dataset as columns\n",
        "    return tokenizer(data[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "dataset = ds.map(tokenize_dataset)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:31:20.790906Z",
          "iopub.execute_input": "2025-07-07T23:31:20.791132Z",
          "iopub.status.idle": "2025-07-07T23:33:28.317802Z",
          "shell.execute_reply.started": "2025-07-07T23:31:20.791115Z",
          "shell.execute_reply": "2025-07-07T23:33:28.316864Z"
        },
        "colab": {
          "referenced_widgets": [
            "7b03de87cf254c27a75e3316d8e37f84",
            "4d4fbab27cb44e8c87baa040bd47bcc8",
            "78f99b6f27e34078ac7b6e2930bb9be1",
            "af8bd1594ed144828b3aa834bc7713f8",
            "2ace2cf004784a54b874c569beac8b0e",
            "2ccf23ed68e8479fbe1ff365bec4768f"
          ]
        },
        "id": "PQVvqNDVRLu_",
        "outputId": "5adf6ff3-7ab5-447b-9be7-fec498431622"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b03de87cf254c27a75e3316d8e37f84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d4fbab27cb44e8c87baa040bd47bcc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78f99b6f27e34078ac7b6e2930bb9be1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af8bd1594ed144828b3aa834bc7713f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ace2cf004784a54b874c569beac8b0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ccf23ed68e8479fbe1ff365bec4768f"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "# Load and compile our model\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(base_model)\n",
        "tf_dataset = model.prepare_tf_dataset(dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer)\n",
        "# Lower learning rates are often better for fine-tuning transformers\n",
        "model.compile()  # No loss argument!\n",
        "\n",
        "model.fit(tf_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-07T23:33:28.318463Z",
          "iopub.execute_input": "2025-07-07T23:33:28.318721Z"
        },
        "colab": {
          "referenced_widgets": [
            "cf3a9ccce289487db01cc1868fc3fe40"
          ]
        },
        "id": "7BSjR8wPRLu_",
        "outputId": "82237427-8bcf-4af5-d3e9-81dd32fededd"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-07-07 23:33:30.061119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751931210.226350      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751931210.277383      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf3a9ccce289487db01cc1868fc3fe40"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1751931224.746483      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nAll PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751931241.523433     126 service.cc:148] XLA service 0x7d3d16063a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1751931241.523907     126 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1751931241.592800     126 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1751931241.703043     126 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": " 903/1562 [================>.............] - ETA: 5:44 - loss: 0.7017",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}