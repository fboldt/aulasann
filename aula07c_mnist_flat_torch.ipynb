{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaDjQKZBPxfDOoxyzxaY4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/aulasann/blob/main/aula07c_mnist_flat_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V0J4UV_i-G9",
        "outputId": "2c197de3-e0cb-4931-b25b-09e3e14bbfb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_flat_images = train_images.reshape((60000, 28 * 28))\n",
        "test_flat_images = test_images.reshape((10000, 28 * 28))\n",
        "print(train_flat_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYj3dFmPoMVD",
        "outputId": "499e5dde-d439-43d2-9cdc-05378b021969"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6lkPyQs5rVF",
        "outputId": "98d37a61-afe3-4df3-f33a-963b447440a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_flat_images_tensor = torch.tensor(train_flat_images, dtype=torch.float32).to(device)\n",
        "train_labels_torch = torch.tensor(train_labels).to(device)\n",
        "test_flat_images_tensor = torch.tensor(test_flat_images, dtype=torch.float32).to(device)\n",
        "test_labels_torch = torch.tensor(test_labels).to(device)\n",
        "\n",
        "train_dataset = TensorDataset(train_flat_images_tensor, train_labels_torch)\n",
        "test_dataset = TensorDataset(test_flat_images_tensor, test_labels_torch)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "class BasicTorchNN(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(BasicTorchNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(28 * 28, 512)\n",
        "    self.fc2 = nn.Linear(512, num_classes)\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = BasicTorchNN(10).to(device)\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch in train_loader:\n",
        "    images, labels = batch\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  total = labels.size(0)\n",
        "  correct = (predicted == labels).sum().item()\n",
        "  print(f\"Accuracy: {correct / total}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl1nDcKZ59bK",
        "outputId": "9d00c972-cac2-4eec-f410-e6c0dbb74a92"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.31326568126678467\n",
            "Epoch 2/5, Loss: 0.10025376826524734\n",
            "Epoch 3/5, Loss: 0.15682794153690338\n",
            "Epoch 4/5, Loss: 0.26227349042892456\n",
            "Epoch 5/5, Loss: 0.042041029781103134\n",
            "Accuracy: 0.9791666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "class TorchWrappedNN(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, epochs=5, batch_size=128, model_fabric=BasicTorchNN):\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.model_fabric = model_fabric\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.labels, ids = np.unique(y, return_inverse=True)\n",
        "\n",
        "    ytensor = torch.tensor(ids, dtype=torch.long).to(device)\n",
        "    xtensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    dataset = TensorDataset(xtensor, ytensor)\n",
        "    loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    self.model = self.model_fabric(len(self.labels)).to(device)\n",
        "    self.optimizer = optim.RMSprop(self.model.parameters(), lr=0.001)\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      for batch in loader:\n",
        "        images, labels = batch\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(images)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "      print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss.item()}\")\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    with torch.no_grad():\n",
        "      xtensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "      outputs = self.model(xtensor)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      return self.labels[predicted.cpu().numpy()]\n",
        "\n",
        "model = TorchWrappedNN(epochs=5, batch_size=128)\n",
        "model.fit(train_flat_images, train_labels)\n",
        "y_pred = model.predict(test_flat_images)\n",
        "accuracy_score(test_labels, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKThNroiqeGi",
        "outputId": "89b73ec4-e7ca-4c8f-f1e6-b0fed7b4f602"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.5393354296684265\n",
            "Epoch 2/5, Loss: 0.26431915163993835\n",
            "Epoch 3/5, Loss: 0.0323740616440773\n",
            "Epoch 4/5, Loss: 0.11840377002954483\n",
            "Epoch 5/5, Loss: 0.06080253794789314\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", TorchWrappedNN())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_flat_images, train_labels)\n",
        "y_pred = pipeline.predict(test_flat_images)\n",
        "accuracy_score(test_labels, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOsrk3WKsovE",
        "outputId": "d1a77fcc-106f-418c-df72-fd98fe924f2d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.1512201875448227\n",
            "Epoch 2/5, Loss: 0.10874402523040771\n",
            "Epoch 3/5, Loss: 0.015678133815526962\n",
            "Epoch 4/5, Loss: 0.02246454916894436\n",
            "Epoch 5/5, Loss: 0.007748025003820658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9734"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "class Divide255(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    return X / 255.0\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", Divide255()),\n",
        "    (\"model\", TorchWrappedNN())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_flat_images, train_labels)\n",
        "y_pred = pipeline.predict(test_flat_images)\n",
        "accuracy_score(test_labels, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmHDbLiQtaPK",
        "outputId": "2e10fc59-a466-4dc2-e466-950831e2abe7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.09070269018411636\n",
            "Epoch 2/5, Loss: 0.06805183738470078\n",
            "Epoch 3/5, Loss: 0.033073168247938156\n",
            "Epoch 4/5, Loss: 0.06653110682964325\n",
            "Epoch 5/5, Loss: 0.04836578294634819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9802"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Shape2Flat(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    return X.reshape((-1, 28 * 28))\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"shape2flat\", Shape2Flat()),\n",
        "    (\"scaler\", Divide255()),\n",
        "    (\"model\", TorchWrappedNN())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_images, train_labels)\n",
        "y_pred = pipeline.predict(test_images)\n",
        "accuracy_score(test_labels, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bLxTvPjuPpn",
        "outputId": "a105b14f-d471-4fa7-9e6c-3b0702cfb52b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.08692585676908493\n",
            "Epoch 2/5, Loss: 0.09133532643318176\n",
            "Epoch 3/5, Loss: 0.07623925805091858\n",
            "Epoch 4/5, Loss: 0.0263067539781332\n",
            "Epoch 5/5, Loss: 0.09983951598405838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9749"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}