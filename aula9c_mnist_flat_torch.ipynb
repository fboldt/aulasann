{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM41m8g5QpuP5EGAe6v+qFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/aulasann/blob/main/aula9c_mnist_flat_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xKjKZ6YpsNF",
        "outputId": "b2494af9-9b07-4190-daf5-83a841a4c0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_flat_images = train_images.reshape((60000, 28 * 28))\n",
        "test_flat_images = test_images.reshape((10000, 28 * 28))\n",
        "train_flat_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5-09P3FxQ-H",
        "outputId": "4c7514d0-dd55-45d1-e5a1-79e0efa46d4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMRNpXfhE4yA",
        "outputId": "6a6d875a-a206-4edc-fbc6-58ba08df87e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_flat_images_tensor = torch.tensor(train_flat_images, dtype=torch.float32)\n",
        "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
        "train_dataset = TensorDataset(train_flat_images_tensor, train_labels_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "test_flat_images_tensor = torch.tensor(test_flat_images, dtype=torch.float32)\n",
        "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "class BasicTorchNN(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(BasicTorchNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(28 * 28, 512)\n",
        "    self.fc2 = nn.Linear(512, num_classes)\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = BasicTorchNN(10)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch in train_loader:\n",
        "    images, labels = batch\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "with torch.no_grad():\n",
        "  test_flat_images_tensor = test_flat_images_tensor.to(device)\n",
        "  test_labels_tensor = test_labels_tensor.to(device)\n",
        "  outputs = model(test_flat_images_tensor)\n",
        "  loss = criterion(outputs, test_labels_tensor)\n",
        "  print(f\"Test Loss: {loss.item()}\")\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  accuracy = (predicted == test_labels_tensor).sum().item() / len(test_labels_tensor)\n",
        "  print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNXLwy3jFC08",
        "outputId": "89afc4f3-0fc1-41a0-af44-9845754686e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.4410780966281891\n",
            "Epoch 2/20, Loss: 0.3133017122745514\n",
            "Epoch 3/20, Loss: 0.367511510848999\n",
            "Epoch 4/20, Loss: 0.11978668719530106\n",
            "Epoch 5/20, Loss: 0.1603698879480362\n",
            "Epoch 6/20, Loss: 0.032896194607019424\n",
            "Epoch 7/20, Loss: 0.06642156094312668\n",
            "Epoch 8/20, Loss: 0.0002354238386033103\n",
            "Epoch 9/20, Loss: 0.0016452261479571462\n",
            "Epoch 10/20, Loss: 0.09129790216684341\n",
            "Epoch 11/20, Loss: 0.013662546873092651\n",
            "Epoch 12/20, Loss: 0.005115180741995573\n",
            "Epoch 13/20, Loss: 0.00021203015057835728\n",
            "Epoch 14/20, Loss: 0.03095310926437378\n",
            "Epoch 15/20, Loss: 0.0005734392325393856\n",
            "Epoch 16/20, Loss: 0.0035133296623826027\n",
            "Epoch 17/20, Loss: 0.0001009546613204293\n",
            "Epoch 18/20, Loss: 2.0206631234032102e-05\n",
            "Epoch 19/20, Loss: 0.002088273176923394\n",
            "Epoch 20/20, Loss: 0.002048423048108816\n",
            "Test Loss: 0.21316586434841156\n",
            "Accuracy: 0.9751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class TorchWrappedNN(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, epochs=5, batch_size=128, model_fabric=BasicTorchNN):\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.model_fabric = model_fabric\n",
        "    self.verbose = True\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.labels, ids = np.unique(y, return_inverse=True)\n",
        "    ytensor = torch.tensor(ids, dtype=torch.long)\n",
        "    xtensor = torch.tensor(X, dtype=torch.float32)\n",
        "    dataset = TensorDataset(xtensor, ytensor)\n",
        "    loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "    self.model = self.model_fabric(len(self.labels))\n",
        "    self.model.to(device)\n",
        "    optimizer = optim.RMSprop(self.model.parameters(), lr=0.0001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(self.epochs):\n",
        "      for batch in loader:\n",
        "        images, labels = batch\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = self.model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      if self.verbose:\n",
        "        print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss.item()}\")\n",
        "    return self\n",
        "  def predict(self, X):\n",
        "    with torch.no_grad():\n",
        "      xtensor = torch.tensor(X, dtype=torch.float32)\n",
        "      xtensor = xtensor.to(device)\n",
        "      outputs = self.model(xtensor)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      return self.labels[predicted.cpu().numpy()]\n",
        "\n",
        "modelo = TorchWrappedNN()\n",
        "modelo.fit(train_flat_images, train_labels)\n",
        "ypred = modelo.predict(test_flat_images)\n",
        "accuracy_score(test_labels, ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5BJqQ3JJA4O",
        "outputId": "067815b1-9520-49e2-8498-be282e6409f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.14165109395980835\n",
            "Epoch 2/5, Loss: 0.058302175253629684\n",
            "Epoch 3/5, Loss: 0.19886456429958344\n",
            "Epoch 4/5, Loss: 0.20076513290405273\n",
            "Epoch 5/5, Loss: 0.054836858063936234\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", MinMaxScaler()),\n",
        "    (\"modelo\", TorchWrappedNN())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_flat_images, train_labels)\n",
        "ypred = pipeline.predict(test_flat_images)\n",
        "accuracy_score(test_labels, ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyvDlsE42Anq",
        "outputId": "976d429b-4655-4fdc-a7af-8cf80ed42916"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.44596007466316223\n",
            "Epoch 2/5, Loss: 0.2545887529850006\n",
            "Epoch 3/5, Loss: 0.17768794298171997\n",
            "Epoch 4/5, Loss: 0.16397058963775635\n",
            "Epoch 5/5, Loss: 0.15477736294269562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9418"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "class Divide255(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    return X / 255.0\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", Divide255()),\n",
        "    (\"modelo\", TorchWrappedNN())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_flat_images, train_labels)\n",
        "ypred = pipeline.predict(test_flat_images)\n",
        "accuracy_score(test_labels, ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qHADNxv2tUf",
        "outputId": "8684ed06-29f5-48e7-98d3-af693cdf64cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.2825833857059479\n",
            "Epoch 2/5, Loss: 0.23002640902996063\n",
            "Epoch 3/5, Loss: 0.2644854187965393\n",
            "Epoch 4/5, Loss: 0.2588998079299927\n",
            "Epoch 5/5, Loss: 0.12089911103248596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9445"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Shape2Flat(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    return X.reshape((-1, 28 * 28))\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", Divide255()),\n",
        "    (\"shape2flat\", Shape2Flat()),\n",
        "    (\"modelo\", TorchWrappedNN(20))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_images, train_labels)\n",
        "ypred = pipeline.predict(test_images)\n",
        "accuracy_score(test_labels, ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUQ3qvk73XvQ",
        "outputId": "9d66936a-2f29-4869-cb14-c823fc2b2883"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.45673128962516785\n",
            "Epoch 2/20, Loss: 0.33961692452430725\n",
            "Epoch 3/20, Loss: 0.2299308180809021\n",
            "Epoch 4/20, Loss: 0.24339406192302704\n",
            "Epoch 5/20, Loss: 0.1098884716629982\n",
            "Epoch 6/20, Loss: 0.09645608067512512\n",
            "Epoch 7/20, Loss: 0.1897345781326294\n",
            "Epoch 8/20, Loss: 0.052187979221343994\n",
            "Epoch 9/20, Loss: 0.14893117547035217\n",
            "Epoch 10/20, Loss: 0.1519756019115448\n",
            "Epoch 11/20, Loss: 0.09983271360397339\n",
            "Epoch 12/20, Loss: 0.06671654433012009\n",
            "Epoch 13/20, Loss: 0.11783039569854736\n",
            "Epoch 14/20, Loss: 0.06224215030670166\n",
            "Epoch 15/20, Loss: 0.050026800483465195\n",
            "Epoch 16/20, Loss: 0.020663077011704445\n",
            "Epoch 17/20, Loss: 0.09875998646020889\n",
            "Epoch 18/20, Loss: 0.08698626607656479\n",
            "Epoch 19/20, Loss: 0.07865362614393234\n",
            "Epoch 20/20, Loss: 0.13838432729244232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.974"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}